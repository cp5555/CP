diff -Naur linux-2.6.38.3/include/linux/in.h linux-2.6.38.3-cp/include/linux/in.h
--- linux-2.6.38.3/include/linux/in.h	2011-04-14 13:03:56.000000000 -0700
+++ linux-2.6.38.3-cp/include/linux/in.h	2014-02-27 12:01:31.000000000 -0800
@@ -189,7 +189,18 @@
   /* Pad to size of `struct sockaddr'. */
   unsigned char		__pad[__SOCK_SIZE__ - sizeof(short int) -
 			sizeof(unsigned short int) - sizeof(struct in_addr)];
+
+  /*
+   *      Display an IP address in readable format.
+   */
+#define NIPQUAD(addr) \
+	((unsigned char *)&addr)[0], \
+	((unsigned char *)&addr)[1], \
+	((unsigned char *)&addr)[2], \
+	((unsigned char *)&addr)[3]
+#define NIPQUAD_FMT "%u.%u.%u.%u"
 };
+
 #define sin_zero	__pad		/* for BSD UNIX comp. -FvK	*/
 
 
diff -Naur linux-2.6.38.3/include/linux/sysctl.h linux-2.6.38.3-cp/include/linux/sysctl.h
--- linux-2.6.38.3/include/linux/sysctl.h	2011-04-14 13:03:56.000000000 -0700
+++ linux-2.6.38.3-cp/include/linux/sysctl.h	2014-03-01 08:27:02.000000000 -0800
@@ -425,6 +425,14 @@
 	NET_TCP_ALLOWED_CONG_CONTROL=123,
 	NET_TCP_MAX_SSTHRESH=124,
 	NET_TCP_FRTO_RESPONSE=125,
+	/* Added by Peng for CP settings */
+	NET_IPV4_TCP_PACK=126,
+	NET_IPV4_TCP_CP=127,
+	NET_IPV4_TCP_DELAYED_ACK=128,
+	NET_IPV4_TCP_DCTCP_ENABLE=129,
+	NET_IPV4_TCP_DCTCP_SHIFT_G=130,
+	NET_IPV4_TCP_RTO_MIN=131,
+	NET_IPV4_TCP_DISORDER_MAX=132,
 };
 
 enum {
diff -Naur linux-2.6.38.3/include/linux/tcp.h linux-2.6.38.3-cp/include/linux/tcp.h
--- linux-2.6.38.3/include/linux/tcp.h	2011-04-14 13:03:56.000000000 -0700
+++ linux-2.6.38.3-cp/include/linux/tcp.h	2014-03-01 08:30:12.000000000 -0800
@@ -68,7 +68,10 @@
 
 #define tcp_flag_word(tp) ( ((union tcp_word_hdr *)(tp))->words [3]) 
 
-enum { 
+enum {
+	/* Added by Peng for CP Flag */  
+	TCP_FLAG_CP2 = __cpu_to_be32(0x02000000),
+	TCP_FLAG_CP1 = __cpu_to_be32(0x01000000), 
 	TCP_FLAG_CWR = __cpu_to_be32(0x00800000),
 	TCP_FLAG_ECE = __cpu_to_be32(0x00400000),
 	TCP_FLAG_URG = __cpu_to_be32(0x00200000),
@@ -396,7 +399,12 @@
 	struct sk_buff_head	out_of_order_queue; /* Out of order segments go here */
 
 	/* SACKs data, these 2 need to be together (see tcp_build_and_update_options) */
-	struct tcp_sack_block duplicate_sack[1]; /* D-SACK block */
+	/* Changed by Peng for PACK */ 
+	union
+	{
+		struct tcp_sack_block duplicate_sack[1]; /* D-SACK block */
+		struct tcp_sack_block pack_acks[1];
+	};
 	struct tcp_sack_block selective_acks[4]; /* The SACKS themselves*/
 
 	struct tcp_sack_block recv_sack_cache[4];
@@ -420,7 +428,6 @@
 	u32	undo_marker;	/* tracking retrans started here. */
 	int	undo_retrans;	/* number of undoable retransmissions. */
 	u32	total_retrans;	/* Total retransmits for entire connection */
-
 	u32	urg_seq;	/* Seq of received urgent pointer */
 	unsigned int		keepalive_time;	  /* time before keep alive takes place */
 	unsigned int		keepalive_intvl;  /* time interval between keep alive probes */
@@ -455,6 +462,16 @@
 	struct tcp_md5sig_info	*md5sig_info;
 #endif
 
+/* DCTCP Specific Parameters */
+ 	u32	acked_bytes_ecn;
+ 	u32	acked_bytes_total;
+ 	u32	prior_ack;
+ 	u32	prior_rcv_nxt;
+ 	u32	dctcp_alpha;
+ 	u32	next_seq;
+ 	u32	ce_state;	/* 0: last pkt was non-ce , 1: last pkt was ce */
+ 	u32	delayed_ack_reserved;
+
 	/* When the cookie options are generated and exchanged, then this
 	 * object holds a reference to them (cookie_values->kref).  Also
 	 * contains related tcp_cookie_transactions fields.
diff -Naur linux-2.6.38.3/include/net/tcp.h linux-2.6.38.3-cp/include/net/tcp.h
--- linux-2.6.38.3/include/net/tcp.h	2011-04-14 13:03:56.000000000 -0700
+++ linux-2.6.38.3-cp/include/net/tcp.h	2014-03-19 20:33:37.000000000 -0700
@@ -243,7 +243,14 @@
 extern int sysctl_tcp_cookie_size;
 extern int sysctl_tcp_thin_linear_timeouts;
 extern int sysctl_tcp_thin_dupack;
-
+/* Added by Peng for CP settings */ 
+extern int sysctl_tcp_pack;
+extern int sysctl_tcp_cp;
+extern int sysctl_tcp_delayed_ack;
+extern int sysctl_tcp_rto_min;
+extern int sysctl_tcp_disorder_max;
+extern int sysctl_tcp_dctcp_enable;
+extern int sysctl_tcp_dctcp_shift_g;
 extern atomic_long_t tcp_memory_allocated;
 extern struct percpu_counter tcp_sockets_allocated;
 extern int tcp_memory_pressure;
@@ -328,7 +335,16 @@
 extern ssize_t tcp_splice_read(struct socket *sk, loff_t *ppos,
 			       struct pipe_inode_info *pipe, size_t len,
 			       unsigned int flags);
-
+/* Added by Peng for sending PACK to sender */			   
+extern int tcp_send_pack(struct sock *sk, struct sk_buff *skb);
+/* Add by Peng for outputing what we want to say */
+extern void tcp_output_pack(struct sk_buff *skb,char* str);
+/* Add by Peng for checking CP Flags */
+extern int tcp_check_cutting_payload(struct sk_buff *skb);
+/* Add by Peng for checking CP Flags */
+extern int ip_check_cutting_payload(struct sk_buff *skb);
+				   
+				   
 static inline void tcp_dec_quickack_mode(struct sock *sk,
 					 const unsigned int pkts)
 {
@@ -544,7 +560,8 @@
 static inline u32 tcp_rto_min(struct sock *sk)
 {
 	struct dst_entry *dst = __sk_dst_get(sk);
-	u32 rto_min = TCP_RTO_MIN;
+	/* Changed by Peng for setting the RTO_min */
+	u32 rto_min = TCP_RTO_MIN * sysctl_tcp_rto_min / 200;
 
 	if (dst && dst_metric_locked(dst, RTAX_RTO_MIN))
 		rto_min = dst_metric_rtt(dst, RTAX_RTO_MIN);
@@ -588,6 +605,9 @@
 #define TCPHDR_URG 0x20
 #define TCPHDR_ECE 0x40
 #define TCPHDR_CWR 0x80
+/* Added by Peng for CP Flag */
+#define TCPHDR_CP1 0x100
+#define TCPHDR_CP2 0x200
 
 /* This is what the send packet queuing engine uses to pass
  * TCP per-packet control information to the transmission code.
diff -Naur linux-2.6.38.3/kernel/sysctl_binary.c linux-2.6.38.3-cp/kernel/sysctl_binary.c
--- linux-2.6.38.3/kernel/sysctl_binary.c	2011-04-14 13:03:56.000000000 -0700
+++ linux-2.6.38.3-cp/kernel/sysctl_binary.c	2014-03-01 08:48:54.000000000 -0800
@@ -416,7 +416,15 @@
 	/* NET_IPV4_IPFRAG_MAX_DIST "ipfrag_max_dist" no longer used */
 
 	{ CTL_INT,	2088 /* NET_IPQ_QMAX */,		"ip_queue_maxlen" },
-
+	/* Added by Peng for CP settings */ 
+	{ CTL_INT,	NET_IPV4_TCP_PACK,	"tcp_pack" },
+	{ CTL_INT,	NET_IPV4_TCP_CP,	"tcp_cp" },
+	{ CTL_INT,	NET_IPV4_TCP_DELAYED_ACK,	"tcp_delayed_ack" },
+	{ CTL_INT,	NET_IPV4_TCP_RTO_MIN,	        "tcp_rto_min" },
+	{ CTL_INT,	NET_IPV4_TCP_DISORDER_MAX,	"tcp_disorder_max" },
+	{ CTL_INT,	NET_IPV4_TCP_DCTCP_ENABLE,	"tcp_dctcp_enable" },
+	{ CTL_INT,	NET_IPV4_TCP_DCTCP_SHIFT_G,	"tcp_dctcp_shift_g" },
+	/* end by CP*/
 	/* NET_TCP_DEFAULT_WIN_SCALE unused */
 	/* NET_TCP_BIC_BETA unused */
 	/* NET_IPV4_TCP_MAX_KA_PROBES unused */
diff -Naur linux-2.6.38.3/Makefile linux-2.6.38.3-cp/Makefile
--- linux-2.6.38.3/Makefile	2011-04-14 13:03:56.000000000 -0700
+++ linux-2.6.38.3-cp/Makefile	2014-02-27 12:01:32.000000000 -0800
@@ -1,7 +1,7 @@
 VERSION = 2
 PATCHLEVEL = 6
 SUBLEVEL = 38
-EXTRAVERSION = .3
+EXTRAVERSION = .3-cp
 NAME = Flesh-Eating Bats with Fangs
 
 # *DOCUMENTATION*
diff -Naur linux-2.6.38.3/net/ipv4/ip_input.c linux-2.6.38.3-cp/net/ipv4/ip_input.c
--- linux-2.6.38.3/net/ipv4/ip_input.c	2011-04-14 13:03:56.000000000 -0700
+++ linux-2.6.38.3-cp/net/ipv4/ip_input.c	2014-03-19 20:10:02.000000000 -0700
@@ -132,6 +132,7 @@
 
 #include <net/snmp.h>
 #include <net/ip.h>
+#include <net/tcp.h>
 #include <net/protocol.h>
 #include <net/route.h>
 #include <linux/skbuff.h>
@@ -419,11 +420,19 @@
 		goto inhdr_error;
 
 	len = ntohs(iph->tot_len);
-	if (skb->len < len) {
+	/* Changed by Peng for CP to ignore IP length */
+	if(ip_check_cutting_payload(skb))
+	{
+		goto ignore_check_trim;
+	}
+	else if (skb->len < len)
+	{
 		IP_INC_STATS_BH(dev_net(dev), IPSTATS_MIB_INTRUNCATEDPKTS);
 		goto drop;
 	} else if (len < (iph->ihl*4))
+	{
 		goto inhdr_error;
+	}
 
 	/* Our transport medium may have padded the buffer out. Now we know it
 	 * is IP we can trim to the true length of the frame.
@@ -433,7 +442,7 @@
 		IP_INC_STATS_BH(dev_net(dev), IPSTATS_MIB_INDISCARDS);
 		goto drop;
 	}
-
+ignore_check_trim:
 	/* Remove any debris in the socket control block */
 	memset(IPCB(skb), 0, sizeof(struct inet_skb_parm));
 
diff -Naur linux-2.6.38.3/net/ipv4/sysctl_net_ipv4.c linux-2.6.38.3-cp/net/ipv4/sysctl_net_ipv4.c
--- linux-2.6.38.3/net/ipv4/sysctl_net_ipv4.c	2011-04-14 13:03:56.000000000 -0700
+++ linux-2.6.38.3-cp/net/ipv4/sysctl_net_ipv4.c	2014-03-02 23:26:56.000000000 -0800
@@ -145,6 +145,57 @@
 		.mode		= 0644,
 		.proc_handler	= proc_dointvec
 	},
+	/* Added by Peng for CP settings */ 
+	{
+		.procname       = "tcp_pack",
+		.data           = &sysctl_tcp_pack,
+		.maxlen         = sizeof(int),
+		.mode           = 0644,
+		.proc_handler   = proc_dointvec
+	},
+	{
+		.procname       = "tcp_cp",
+		.data           = &sysctl_tcp_pack,
+		.maxlen         = sizeof(int),
+		.mode           = 0644,
+		.proc_handler   = proc_dointvec
+	},
+ 	{
+		.procname	= "tcp_delayed_ack",
+		.data		= &sysctl_tcp_delayed_ack,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec
+	},
+	{
+		.procname	= "tcp_rto_min",
+		.data		= &sysctl_tcp_rto_min,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec
+	},
+	{
+		.procname	= "tcp_disorder_max",
+		.data		= &sysctl_tcp_disorder_max,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec
+	},
+
+	{
+		.procname	= "tcp_dctcp_enable",
+		.data		= &sysctl_tcp_dctcp_enable,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec
+	},
+	{
+		.procname	= "tcp_dctcp_shift_g",
+		.data		= &sysctl_tcp_dctcp_shift_g,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec
+	},
 	{
 		.procname	= "tcp_retrans_collapse",
 		.data		= &sysctl_tcp_retrans_collapse,
diff -Naur linux-2.6.38.3/net/ipv4/tcp_input.c linux-2.6.38.3-cp/net/ipv4/tcp_input.c
--- linux-2.6.38.3/net/ipv4/tcp_input.c	2011-04-14 13:03:56.000000000 -0700
+++ linux-2.6.38.3-cp/net/ipv4/tcp_input.c	2014-03-19 20:30:27.000000000 -0700
@@ -72,6 +72,21 @@
 #include <linux/ipsec.h>
 #include <asm/unaligned.h>
 #include <net/netdma.h>
+/* Added by Peng for tcp_output_pack */ 
+#include <linux/in.h>
+/* Added by Peng for CP settings */ 
+int sysctl_tcp_pack __read_mostly = 0;
+EXPORT_SYMBOL(sysctl_tcp_pack);
+int sysctl_tcp_cp __read_mostly = 0;
+EXPORT_SYMBOL(sysctl_tcp_cp);
+int sysctl_tcp_disorder_max __read_mostly = 0;
+EXPORT_SYMBOL(sysctl_tcp_disorder_max);
+int sysctl_tcp_delayed_ack __read_mostly = 1;
+EXPORT_SYMBOL(sysctl_tcp_delayed_ack);
+int sysctl_tcp_dctcp_enable __read_mostly;
+EXPORT_SYMBOL(sysctl_tcp_dctcp_enable);
+int sysctl_tcp_dctcp_shift_g  __read_mostly = 4; /* g=1/2^4 */
+EXPORT_SYMBOL(sysctl_tcp_dctcp_shift_g);
 
 int sysctl_tcp_timestamps __read_mostly = 1;
 int sysctl_tcp_window_scaling __read_mostly = 1;
@@ -112,10 +127,11 @@
 #define FLAG_DSACKING_ACK	0x800 /* SACK blocks contained D-SACK info */
 #define FLAG_NONHEAD_RETRANS_ACKED	0x1000 /* Non-head rexmitted data was ACKed */
 #define FLAG_SACK_RENEGING	0x2000 /* snd_una advanced to a sacked seq */
+#define FLAG_PACK_ACK    	0x4000 /* Add by Peng for checking CP Flags */
 
 #define FLAG_ACKED		(FLAG_DATA_ACKED|FLAG_SYN_ACKED)
 #define FLAG_NOT_DUP		(FLAG_DATA|FLAG_WIN_UPDATE|FLAG_ACKED)
-#define FLAG_CA_ALERT		(FLAG_DATA_SACKED|FLAG_ECE)
+#define FLAG_CA_ALERT		(FLAG_DATA_SACKED|FLAG_ECE|FLAG_PACK_ACK)
 #define FLAG_FORWARD_PROGRESS	(FLAG_ACKED|FLAG_DATA_SACKED)
 #define FLAG_ANY_PROGRESS	(FLAG_FORWARD_PROGRESS|FLAG_SND_UNA_ADVANCED)
 
@@ -217,16 +233,66 @@
 	tp->ecn_flags &= ~TCP_ECN_DEMAND_CWR;
 }
 
-static inline void TCP_ECN_check_ce(struct tcp_sock *tp, struct sk_buff *skb)
+//static inline void TCP_ECN_check_ce(struct tcp_sock *tp, struct sk_buff *skb)
+static inline void TCP_ECN_dctcp_check_ce(struct sock *sk, struct tcp_sock *tp, struct sk_buff *skb)
 {
-	if (tp->ecn_flags & TCP_ECN_OK) {
-		if (INET_ECN_is_ce(TCP_SKB_CB(skb)->flags))
+	if (tp->ecn_flags & TCP_ECN_OK) 
+	{
+		u32 temp_rcv_nxt;
+		if (INET_ECN_is_ce(TCP_SKB_CB(skb)->flags)) 
+		{
+			/* rcv_nxt is already update in previous process (tcp_rcv_established) */
+			if(sysctl_tcp_dctcp_enable) 
+			{
+				/* state has changed from CE=0 to CE=1 && delayed ack has not sent yet */
+				if(tp->ce_state == 0 && tp->delayed_ack_reserved) 
+				{
+					/* save current rcv_nxt */
+					temp_rcv_nxt = tp->rcv_nxt;
+					/* generate previous ack with CE=0 */
+					tp->ecn_flags &= ~TCP_ECN_DEMAND_CWR;
+					tp->rcv_nxt = tp->prior_rcv_nxt;
+					/* printk("CE=0 rcv_nxt= %u nxt= %u\n",tp->rcv_nxt, temp_rcv_nxt);  */
+					tcp_send_ack(sk);
+					/* recover current rcv_nxt */
+					tp->rcv_nxt = temp_rcv_nxt;
+				}
+				tp->ce_state = 1;
+			}
 			tp->ecn_flags |= TCP_ECN_DEMAND_CWR;
-		/* Funny extension: if ECT is not set on a segment,
-		 * it is surely retransmit. It is not in ECN RFC,
-		 * but Linux follows this rule. */
-		else if (INET_ECN_is_not_ect((TCP_SKB_CB(skb)->flags)))
+			/* Funny extension: if ECT is not set on a segment,
+			* it is surely retransmit. It is not in ECN RFC,
+			* but Linux follows this rule. */
+		} 
+		else if (INET_ECN_is_not_ect((TCP_SKB_CB(skb)->flags))) 
+		{
 			tcp_enter_quickack_mode((struct sock *)tp);
+		}
+		else
+		{
+			/* It has ECT but it doesn't have CE */
+			if(sysctl_tcp_dctcp_enable) 
+			{
+				if(tp->ce_state != 0 && tp->delayed_ack_reserved) 
+				{
+			
+					/* save current rcv_nxt */
+					temp_rcv_nxt = tp->rcv_nxt;
+					/* generate previous ack with CE=1 */
+					tp->ecn_flags |= TCP_ECN_DEMAND_CWR;
+					tp->rcv_nxt = tp->prior_rcv_nxt;
+					/* printk("CE=1 rcv_nxt= %u nxt= %u\n",tp->rcv_nxt, temp_rcv_nxt);  */
+					tcp_send_ack(sk);
+					/* recover current rcv_nxt */
+					tp->rcv_nxt = temp_rcv_nxt;
+				}
+				tp->ce_state = 0;
+				/* deassert only when DCTCP is enabled */
+				tp->ecn_flags &= ~TCP_ECN_DEMAND_CWR;
+			}
+		}
+		/* set current rcv_nxt to prior_rcv_nxt */
+		tp->prior_rcv_nxt = tp->rcv_nxt;
 	}
 }
 
@@ -581,6 +647,7 @@
 		 */
 		tcp_incr_quickack(sk);
 		icsk->icsk_ack.ato = TCP_ATO_MIN;
+		tp->ce_state = 0;
 	} else {
 		int m = now - icsk->icsk_ack.lrcvtime;
 
@@ -601,7 +668,7 @@
 	}
 	icsk->icsk_ack.lrcvtime = now;
 
-	TCP_ECN_check_ce(tp, skb);
+	TCP_ECN_dctcp_check_ce(sk, tp, skb);
 
 	if (skb->len >= 128)
 		tcp_grow_window(sk, skb);
@@ -827,14 +894,49 @@
 	struct tcp_sock *tp = tcp_sk(sk);
 	const struct inet_connection_sock *icsk = inet_csk(sk);
 
+	__u32 ssthresh_old; 
+	__u32 cwnd_old;
+	__u32 cwnd_new;
+	
 	tp->prior_ssthresh = 0;
 	tp->bytes_acked = 0;
 	if (icsk->icsk_ca_state < TCP_CA_CWR) {
 		tp->undo_marker = 0;
-		if (set_ssthresh)
-			tp->snd_ssthresh = icsk->icsk_ca_ops->ssthresh(sk);
-		tp->snd_cwnd = min(tp->snd_cwnd,
-				   tcp_packets_in_flight(tp) + 1U);
+
+				if(!sysctl_tcp_dctcp_enable) {
+
+		  if (set_ssthresh)
+		    tp->snd_ssthresh = icsk->icsk_ca_ops->ssthresh(sk);
+
+		  tp->snd_cwnd = min(tp->snd_cwnd,
+				     tcp_packets_in_flight(tp) + 1U);
+		  
+		}else {
+
+		  cwnd_new = max (tp->snd_cwnd - ((tp->snd_cwnd * tp->dctcp_alpha)>>11) , 2U);
+
+		  if(set_ssthresh) {
+		    
+		    ssthresh_old = tp->snd_ssthresh;
+		    tp->snd_ssthresh =  cwnd_new;
+		    
+		    /* printk("%llu alpha= %d ssth old= %d new= %d\n", */
+		    /* 		    			   ktime_to_us(ktime_get_real()), */
+		    /* 		    			   tp->dctcp_alpha, */
+		    /* 		    			   ssthresh_old, */
+		    /* 		    			   tp->snd_ssthresh); */
+		  }
+		  
+		  cwnd_old = tp->snd_cwnd;
+		  tp->snd_cwnd = cwnd_new;
+		  
+		  /* printk("%llu alpha= %d cwnd old= %d new= %d\n", */
+		  /* 		  			 ktime_to_us(ktime_get_real()), */
+		  /* 		  			 tp->dctcp_alpha, */
+		  /* 		  			 cwnd_old, */
+		  /* 		  			 tp->snd_cwnd); */
+		}
+		
 		tp->snd_cwnd_cnt = 0;
 		tp->high_seq = tp->snd_nxt;
 		tp->snd_cwnd_stamp = tcp_time_stamp;
@@ -1195,6 +1297,202 @@
 		tp->lost_retrans_low = new_low_seq;
 }
 
+/* Add by Peng for checking PACK option */
+static int tcp_is_packblock_valid(struct tcp_sock *tp,u32 start_seq, u32 end_seq)
+{
+	if (after(end_seq, tp->snd_nxt) || !before(start_seq, end_seq))
+		return 0;
+
+	if (!before(start_seq, tp->snd_nxt))
+		return 0;
+
+	if (!before(start_seq, tp->snd_una))
+		return 1;
+
+	return 0;
+}
+
+/* Add by Peng for adding PACK option to ACK */
+static void tcp_pack_set(struct sock *sk, u32 seq, u32 end_seq)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	if (tcp_is_sack(tp) && sysctl_tcp_cp)
+    {
+		tp->rx_opt.dsack = 1;
+		tp->pack_acks[0].start_seq = end_seq;
+		if(before(seq,tp->rcv_nxt))
+		{
+			tp->pack_acks[0].end_seq = tp->rcv_nxt;
+		}
+		else
+		{
+			tp->pack_acks[0].end_seq = seq;
+		}
+	}
+}
+
+/* Add by Peng for ckecking skb whether fit the PACK option */
+static int tcp_match_skb_to_pack(struct sock *sk, struct sk_buff *skb, u32 start_seq, u32 end_seq)
+{
+	int err;
+	unsigned int pkt_len;
+	unsigned int mss;
+	
+	if( !after(end_seq, TCP_SKB_CB(skb)->seq) || !before(start_seq, TCP_SKB_CB(skb)->end_seq) || (skb->len == 0) )
+	{
+		return 0;
+	}
+	
+	if((!after(start_seq, TCP_SKB_CB(skb)->seq) && !before(end_seq, TCP_SKB_CB(skb)->end_seq)) || (tcp_skb_pcount(skb) < 2))
+	{
+		return 1;
+	}
+	else
+	{
+		mss = tcp_skb_mss(skb);
+		/* head is pack */
+		if (after(start_seq, TCP_SKB_CB(skb)->seq))
+		{
+			pkt_len = start_seq - TCP_SKB_CB(skb)->seq;
+			if (pkt_len >= mss)
+			{
+				pkt_len = (pkt_len / mss) * mss;
+				err = tcp_fragment(sk, skb, pkt_len, mss);
+				if(err == 0)
+				{
+					return 0;
+				}	
+			}
+		}
+		
+		if(before(end_seq, TCP_SKB_CB(skb)->end_seq))
+		{
+			pkt_len = end_seq - TCP_SKB_CB(skb)->seq;
+			if (pkt_len < mss)
+			{
+				pkt_len = mss;
+			}
+			else
+			{
+				pkt_len = (pkt_len / mss) * mss;
+			}	
+			tcp_fragment(sk, skb, pkt_len, mss);
+		}
+		return 1;
+	}
+}
+
+/* Add by Peng for checking whether receive the old PACK  */
+int tcp_check_old_pack(struct sock *sk, u32 seq, u32 end_seq)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct tcp_sack_block *sp = tp->selective_acks;
+	int this_sack;
+	if(!after(end_seq,seq) || !after(end_seq,tp->rcv_nxt))
+	{
+		tcp_output_pack(NULL,"receive old cutting payload");
+		printk(KERN_INFO "old cutting payload! SEQ:%u END_SEQ:%u RCV_NXT;%u",seq,end_seq,tp->rcv_nxt);
+		return 1;
+	}
+	
+	
+	for (this_sack = 0; this_sack < tp->rx_opt.num_sacks;this_sack++)
+	{
+		if( !after(sp[this_sack].start_seq,seq) && !before(sp[this_sack].end_seq,end_seq))
+		{
+			tcp_output_pack(NULL,"receive old cutting payload");
+			printk(KERN_INFO "old cutting payload! SEQ:%u END_SEQ:%u SACK_SEQ:%u SACK_END_SEQ:%u",seq,end_seq,sp[this_sack].start_seq,sp[this_sack].end_seq);
+			return 1;
+		}
+	}
+	return 0;
+}
+
+/* Added by Peng for sending PACK to sender */
+int tcp_pack_ack(struct sock *sk, struct sk_buff *skb)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	if (before(TCP_SKB_CB(skb)->seq,TCP_SKB_CB(skb)->end_seq)&& 
+	     !tcp_check_old_pack( sk, TCP_SKB_CB(skb)->seq, TCP_SKB_CB(skb)->end_seq) && tcp_is_sack(tp))
+	{
+		tcp_pack_set(sk,TCP_SKB_CB(skb)->seq,TCP_SKB_CB(skb)->end_seq);
+		tcp_enter_quickack_mode(sk);
+		tcp_send_ack(sk);
+	}
+	return 0;
+}
+EXPORT_SYMBOL(tcp_pack_ack);
+
+/* Add by Peng for outputing what we want to say */
+void tcp_output_pack(struct sk_buff *skb,char* str)
+{
+	const struct iphdr *iph;
+	const struct tcphdr *th;
+	if(skb != NULL)
+	{
+		iph = ip_hdr(skb);
+		th = tcp_hdr(skb);
+		printk(KERN_INFO "%s,SRC:%u.%u.%u.%u DST:%u.%u.%u.%u res1:%u",str,NIPQUAD(iph->saddr),NIPQUAD(iph->daddr),th->res1);
+	}
+	else
+	{
+		printk(KERN_INFO "%s",str);
+	}
+}
+EXPORT_SYMBOL(tcp_output_pack);
+
+/* Add by Peng for checking CP Flags */
+int tcp_check_cutting_payload(struct sk_buff *skb)
+{
+	const struct tcphdr *th;
+	th = tcp_hdr(skb);
+	if (sysctl_tcp_cp && (tcp_flag_word(th) & TCP_FLAG_CP1) && (tcp_flag_word(th) & TCP_FLAG_CP2))
+	{
+		return 1;
+	}
+	else
+	{
+		return 0;
+	}
+		
+}
+EXPORT_SYMBOL(tcp_check_cutting_payload);
+
+/* Add by Peng for checking CP Flags */
+int ip_check_cutting_payload(struct sk_buff *skb)
+{
+	const struct tcphdr *th;
+	th = (struct tcphdr *)(skb_network_header(skb)+ip_hdrlen(skb));
+	if (sysctl_tcp_cp && (tcp_flag_word(th) & TCP_FLAG_CP1) && (tcp_flag_word(th) & TCP_FLAG_CP2))
+	{
+		return 1;
+	}
+	else
+	{
+		return 0;
+	}
+		
+}
+EXPORT_SYMBOL(ip_check_cutting_payload);
+
+
+
+
+/* Add by Peng for checking PACK option*/
+static int tcp_check_pack(struct sock *sk,struct tcp_sack_block_wire *sp)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	u32 start_seq_0 = get_unaligned_be32(&(sp[0].start_seq));
+	u32 end_seq_0 = get_unaligned_be32(&(sp[0].end_seq));
+	
+	if ( after(start_seq_0, end_seq_0) )
+	{
+		tp->rx_opt.sack_ok |= 8;
+		return 1;
+	}
+	return 0;
+}
+
 static int tcp_check_dsack(struct sock *sk, struct sk_buff *ack_skb,
 			   struct tcp_sack_block_wire *sp, int num_sacks,
 			   u32 prior_snd_una)
@@ -1724,7 +2022,12 @@
 	int found_dup_sack = 0;
 	int i, j;
 	int first_sack_index;
-
+	
+	/* Add by Peng for dealing with PACK option */
+	struct tcp_sack_block pack_option;
+	struct sk_buff *pack_skb = NULL;
+	int found_pack = 0;
+	
 	state.flag = 0;
 	state.reord = tp->packets_out;
 
@@ -1733,12 +2036,20 @@
 			tp->fackets_out = 0;
 		tcp_highest_sack_reset(sk);
 	}
-
-	found_dup_sack = tcp_check_dsack(sk, ack_skb, sp_wire,
-					 num_sacks, prior_snd_una);
-	if (found_dup_sack)
-		state.flag |= FLAG_DSACKING_ACK;
-
+	
+	/* Changed by Peng for making decision for PACK option or DSACK */
+	if(sysctl_tcp_pack)
+	{
+		found_pack = tcp_check_pack(sk,sp_wire);
+	}
+	
+	if(found_pack == 0)
+	{
+		found_dup_sack = tcp_check_dsack(sk, ack_skb, sp_wire, num_sacks, prior_snd_una);
+		if (found_dup_sack)
+			state.flag |= FLAG_DSACKING_ACK;
+	}
+	
 	/* Eliminate too old ACKs, but take into
 	 * account more or less fresh ones, they can
 	 * contain valid SACK info.
@@ -1751,15 +2062,35 @@
 
 	used_sacks = 0;
 	first_sack_index = 0;
-	for (i = 0; i < num_sacks; i++) {
+	for (i = 0; i < num_sacks; i++)	
+	{
 		int dup_sack = !i && found_dup_sack;
-
+		/* Add by Peng for recording PACK option */
+		int pack_tag = !i && found_pack;
 		sp[used_sacks].start_seq = get_unaligned_be32(&sp_wire[i].start_seq);
 		sp[used_sacks].end_seq = get_unaligned_be32(&sp_wire[i].end_seq);
-
-		if (!tcp_is_sackblock_valid(tp, dup_sack,
-					    sp[used_sacks].start_seq,
-					    sp[used_sacks].end_seq)) {
+		
+		/* Add by Peng for recording PACK option */
+		if(pack_tag)
+		{
+			sp[used_sacks].start_seq = get_unaligned_be32(&sp_wire[i].end_seq);
+			sp[used_sacks].end_seq = get_unaligned_be32(&sp_wire[i].start_seq);
+			if (!tcp_is_packblock_valid(tp,sp[used_sacks].start_seq,sp[used_sacks].end_seq))
+			{
+				//tcp_output_pack(NULL,"receive old pack option");
+				found_pack = 0;
+				first_sack_index = -1;
+				continue;
+			}
+			else
+			{
+				pack_option.start_seq = get_unaligned_be32(&sp_wire[i].end_seq);
+				pack_option.end_seq = get_unaligned_be32(&sp_wire[i].start_seq);
+			}
+			//tcp_output_pack(NULL,"check pack is right!!");
+		}
+		else if (!tcp_is_sackblock_valid(tp, dup_sack,sp[used_sacks].start_seq,sp[used_sacks].end_seq))
+		{
 			int mib_idx;
 
 			if (dup_sack) {
@@ -1784,7 +2115,7 @@
 		/* Ignore very old stuff early */
 		if (!after(sp[used_sacks].end_seq, prior_snd_una))
 			continue;
-
+			
 		used_sacks++;
 	}
 
@@ -1793,7 +2124,7 @@
 		for (j = 0; j < i; j++) {
 			if (after(sp[j].start_seq, sp[j + 1].start_seq)) {
 				swap(sp[j], sp[j + 1]);
-
+				
 				/* Track where the first SACK block goes to */
 				if (j == first_sack_index)
 					first_sack_index = j + 1;
@@ -1820,13 +2151,16 @@
 		u32 start_seq = sp[i].start_seq;
 		u32 end_seq = sp[i].end_seq;
 		int dup_sack = (found_dup_sack && (i == first_sack_index));
+		/* Add by Peng for recording PACK option */
+		int pack_tag = (found_pack && (i == first_sack_index));
 		struct tcp_sack_block *next_dup = NULL;
 
 		if (found_dup_sack && ((i + 1) == first_sack_index))
 			next_dup = &sp[i + 1];
 
 		/* Event "B" in the comment above. */
-		if (after(end_seq, tp->high_seq))
+		/* Changed by Peng for parsing PACK option */
+		if (!pack_tag && after(end_seq, tp->high_seq))
 			state.flag |= FLAG_DATA_LOST;
 
 		/* Skip too early cached blocks */
@@ -1834,6 +2168,17 @@
 		       !before(start_seq, cache->end_seq))
 			cache++;
 
+		/* Add by Peng for parsing PACK option */
+		if(pack_tag)
+		{
+			
+			//tcp_output_pack(NULL,"found pack skb!!");
+			skb = tcp_sacktag_skip(skb, sk, &state, start_seq);
+			pack_skb = skb;
+			i++;
+			continue;
+		}
+		
 		/* Can skip some work by looking recv_sack_cache? */
 		if (tcp_sack_cache_ok(tp, cache) && !dup_sack &&
 		    after(end_seq, cache->start_seq)) {
@@ -1841,22 +2186,20 @@
 			/* Head todo? */
 			if (before(start_seq, cache->start_seq)) {
 				skb = tcp_sacktag_skip(skb, sk, &state,
-						       start_seq);
+						       start_seq);			
 				skb = tcp_sacktag_walk(skb, sk, next_dup,
 						       &state,
 						       start_seq,
 						       cache->start_seq,
 						       dup_sack);
 			}
-
+			
 			/* Rest of the block already fully processed? */
 			if (!after(end_seq, cache->end_seq))
 				goto advance_sp;
-
 			skb = tcp_maybe_skipping_dsack(skb, sk, next_dup,
 						       &state,
 						       cache->end_seq);
-
 			/* ...tail remains todo... */
 			if (tcp_highest_sack_seq(tp) == cache->end_seq) {
 				/* ...but better entrypoint exists! */
@@ -1867,7 +2210,7 @@
 				cache++;
 				goto walk;
 			}
-
+			
 			skb = tcp_sacktag_skip(skb, sk, &state, cache->end_seq);
 			/* Check overlap against next cached too (past this one already) */
 			cache++;
@@ -1897,13 +2240,58 @@
 	}
 
 	/* Clear the head of the cache sack blocks so we can skip it next time */
-	for (i = 0; i < ARRAY_SIZE(tp->recv_sack_cache) - used_sacks; i++) {
+	/* Changed by Peng for parsing PACK option */
+	for (i = 0; i < ARRAY_SIZE(tp->recv_sack_cache) - used_sacks + found_pack; i++)
+	{
 		tp->recv_sack_cache[i].start_seq = 0;
 		tp->recv_sack_cache[i].end_seq = 0;
 	}
+	
 	for (j = 0; j < used_sacks; j++)
+	{
+		/* Changed by Peng for parsing PACK option */
+		if( j == first_sack_index && found_pack)
+		{
+			u32 pack_start_seq = sp[j].start_seq;
+			u32 pack_end_seq = sp[j].end_seq;
+			skb = pack_skb;
+			tcp_for_write_queue_from(skb,sk)
+			{
+				int in_pack;
+				//tcp_output_pack(NULL,"where is pack skb!!");
+				if (skb == tcp_send_head(sk))
+					break;
+				if (after(TCP_SKB_CB(skb)->end_seq,pack_start_seq))
+				{
+					//tcp_output_pack(NULL,"found pack skb!!");
+					if(!before(TCP_SKB_CB(skb)->seq,pack_end_seq))
+					{
+						break;
+					}
+					if(TCP_SKB_CB(skb)->sacked & TCPCB_SACKED_ACKED)
+					{
+						continue;
+					}
+					in_pack = tcp_match_skb_to_pack(sk,skb,pack_start_seq,pack_end_seq);
+					/* Change by Peng for adding lost*/
+					if(in_pack)
+					{
+						state.flag |= FLAG_PACK_ACK;
+						//tcp_output_pack(NULL,"mark lost skb!!");
+						if(TCP_SKB_CB(skb)->sacked & TCPCB_SACKED_RETRANS)
+						{
+							TCP_SKB_CB(skb)->sacked &= ~TCPCB_SACKED_RETRANS;
+							tp->retrans_out -= tcp_skb_pcount(skb);
+						}
+						tcp_skb_mark_lost_uncond_verify(tp, skb);
+					}
+				}
+			}
+			continue;
+		}
 		tp->recv_sack_cache[i++] = sp[j];
-
+	}
+	
 	tcp_mark_lost_retrans(sk);
 
 	tcp_verify_left_out(tp);
@@ -2233,7 +2621,6 @@
 	tcp_for_write_queue(skb, sk) {
 		if (skb == tcp_send_head(sk))
 			break;
-
 		if (TCP_SKB_CB(skb)->sacked & TCPCB_RETRANS)
 			tp->undo_marker = 0;
 		TCP_SKB_CB(skb)->sacked &= (~TCPCB_TAGBITS)|TCPCB_SACKED_ACKED;
@@ -2420,7 +2807,9 @@
 	/* Trick#1: The loss is proven. */
 	if (tp->lost_out)
 		return 1;
-
+	/* Add by Peng for setting out-of-order to infinity */
+	if(sysctl_tcp_disorder_max == 1)
+		return 0;
 	/* Not-A-Trick#2 : Classic rule... */
 	if (tcp_dupack_heuristics(tp) > tp->reordering)
 		return 1;
@@ -2857,7 +3246,10 @@
 		tcp_try_keep_open(sk);
 		tcp_moderate_cwnd(tp);
 	} else {
-		tcp_cwnd_down(sk, flag);
+		if(!sysctl_tcp_dctcp_enable)
+		{
+			tcp_cwnd_down(sk, flag);
+		}
 	}
 }
 
@@ -3622,6 +4014,9 @@
 	int prior_packets;
 	int frto_cwnd = 0;
 
+	__u32 alpha_old;
+	__u32 acked_bytes;
+	
 	/* If the ack is older than previous acks
 	 * then we can probably ignore it.
 	 */
@@ -3678,6 +4073,57 @@
 		tcp_ca_event(sk, CA_EVENT_SLOW_ACK);
 	}
 
+	/* START: DCTCP Processing */
+
+	/* calc acked bytes */
+	if(after(ack,tp->prior_ack)) 
+	{
+		acked_bytes = ack - tp->prior_ack;
+	} 
+	else 
+	{
+	  
+		if(flag & FLAG_WIN_UPDATE)
+		{
+			/* Don't count when it is Window Updated ACK */
+			acked_bytes = 0; 
+			/* printk("acked_byte=0\n"); */
+		}
+		else 
+		{
+			/* Count duplicate ACKs for Retransmission packets and so on as MSS size */
+			acked_bytes = inet_csk(sk)->icsk_ack.rcv_mss;
+		}
+	}
+
+	if(flag & FLAG_ECE) 
+		tp->acked_bytes_ecn += acked_bytes;
+
+	tp->acked_bytes_total += acked_bytes;
+
+	tp->prior_ack = ack;
+
+	/* Expired RTT */
+    if (!before(tp->snd_una,tp->next_seq))
+	{
+
+		/* For avoiding denominator == 1 */
+		if(tp->acked_bytes_total == 0) tp->acked_bytes_total = 1;
+			alpha_old = tp->dctcp_alpha; 
+		/* alpha = (1-g) * alpha + g * F */
+		tp->dctcp_alpha = alpha_old - (alpha_old >> sysctl_tcp_dctcp_shift_g)
+			+ (tp->acked_bytes_ecn << (10 - sysctl_tcp_dctcp_shift_g)) / tp->acked_bytes_total;  
+	  
+		if(tp->dctcp_alpha > 1024) tp->dctcp_alpha = 1024; /* round to 0-1024 */
+			/* printk("bytes_ecn= %d total= %d alpha: old= %d new= %d\n", */
+			/* tp->acked_bytes_ecn, tp->acked_bytes_total, alpha_old, tp->dctcp_alpha); */
+		  tp->acked_bytes_ecn = 0;
+		tp->acked_bytes_total = 0;
+		tp->next_seq = tp->snd_nxt;
+    }
+
+	/* END: DCTCP Processing */
+	
 	/* We passed data and got it acked, remove any soft error
 	 * log. Something worked...
 	 */
@@ -4478,7 +4924,7 @@
 		goto queue_and_out;
 	}
 
-	TCP_ECN_check_ce(tp, skb);
+	TCP_ECN_dctcp_check_ce(sk,tp, skb);
 
 	if (tcp_try_rmem_schedule(sk, skb->truesize))
 		goto drop;
@@ -4930,6 +5376,8 @@
 	    /* We ACK each frame or... */
 	    tcp_in_quickack_mode(sk) ||
 	    /* We have out of order data. */
+		/* Delayed ACK is disabled or ... */
+	    sysctl_tcp_delayed_ack == 0 ||
 	    (ofo_possible && skb_peek(&tp->out_of_order_queue))) {
 		/* Then ack it now */
 		tcp_send_ack(sk);
@@ -5258,6 +5706,12 @@
 	 *	 space for instance)
 	 *	PSH flag is ignored.
 	 */
+        /* Add by Peng for sending PACK */
+        if( tcp_check_cutting_payload(skb))
+        {
+                tcp_pack_ack(sk,skb);
+                goto discard;
+        }
 
 	if ((tcp_flag_word(th) & TCP_HP_BITS) == tp->pred_flags &&
 	    TCP_SKB_CB(skb)->seq == tp->rcv_nxt &&
@@ -5268,7 +5722,7 @@
 		 * is automatically equal to th->doff*4 due to pred_flags
 		 * match.
 		 */
-
+		 
 		/* Check timestamp */
 		if (tcp_header_len == sizeof(struct tcphdr) + TCPOLEN_TSTAMP_ALIGNED) {
 			/* No? Slow path! */
diff -Naur linux-2.6.38.3/net/ipv4/tcp_ipv4.c linux-2.6.38.3-cp/net/ipv4/tcp_ipv4.c
--- linux-2.6.38.3/net/ipv4/tcp_ipv4.c	2011-04-14 13:03:56.000000000 -0700
+++ linux-2.6.38.3-cp/net/ipv4/tcp_ipv4.c	2014-03-19 19:15:47.000000000 -0700
@@ -85,7 +85,9 @@
 int sysctl_tcp_tw_reuse __read_mostly;
 int sysctl_tcp_low_latency __read_mostly;
 EXPORT_SYMBOL(sysctl_tcp_low_latency);
-
+/* Add by Peng for setting RTO_min */
+int sysctl_tcp_rto_min __read_mostly = 200; 
+EXPORT_SYMBOL(sysctl_tcp_rto_min);
 
 #ifdef CONFIG_TCP_MD5SIG
 static struct tcp_md5sig_key *tcp_v4_md5_do_lookup(struct sock *sk,
@@ -1565,8 +1567,12 @@
 		return 0;
 	}
 
+ 	
+
 	if (skb->len < tcp_hdrlen(skb) || tcp_checksum_complete(skb))
+	{
 		goto csum_err;
+	}
 
 	if (sk->sk_state == TCP_LISTEN) {
 		struct sock *nsk = tcp_v4_hnd_req(sk, skb);
@@ -1641,23 +1647,38 @@
 	 * Packet length and doff are validated by header prediction,
 	 * provided case of th->doff==0 is eliminated.
 	 * So, we defer the checks. */
+
+
+	/* Add by Peng for jumping checksum */
+	if(tcp_check_cutting_payload(skb))
+	{
+		skb->ip_summed = CHECKSUM_UNNECESSARY;		
+	}
+
 	if (!skb_csum_unnecessary(skb) && tcp_v4_checksum_init(skb))
 		goto bad_packet;
 
 	th = tcp_hdr(skb);
 	iph = ip_hdr(skb);
 	TCP_SKB_CB(skb)->seq = ntohl(th->seq);
-	TCP_SKB_CB(skb)->end_seq = (TCP_SKB_CB(skb)->seq + th->syn + th->fin +
-				    skb->len - th->doff * 4);
+	/* Changed by Peng for getting packet length */
+	if(tcp_check_cutting_payload(skb))
+	{
+		TCP_SKB_CB(skb)->end_seq = (TCP_SKB_CB(skb)->seq + th->syn + th->fin + ntohs(iph->tot_len) - iph->ihl * 4 - th->doff * 4);
+	}
+	else
+	{
+		TCP_SKB_CB(skb)->end_seq = (TCP_SKB_CB(skb)->seq + th->syn + th->fin + skb->len - th->doff * 4);
+	}
 	TCP_SKB_CB(skb)->ack_seq = ntohl(th->ack_seq);
 	TCP_SKB_CB(skb)->when	 = 0;
 	TCP_SKB_CB(skb)->flags	 = iph->tos;
 	TCP_SKB_CB(skb)->sacked	 = 0;
-
+	
 	sk = __inet_lookup_skb(&tcp_hashinfo, skb, th->source, th->dest);
 	if (!sk)
 		goto no_tcp_socket;
-
+		
 process:
 	if (sk->sk_state == TCP_TIME_WAIT)
 		goto do_time_wait;
diff -Naur linux-2.6.38.3/net/ipv4/tcp_output.c linux-2.6.38.3-cp/net/ipv4/tcp_output.c
--- linux-2.6.38.3/net/ipv4/tcp_output.c	2011-04-14 13:03:56.000000000 -0700
+++ linux-2.6.38.3-cp/net/ipv4/tcp_output.c	2014-03-19 19:59:03.000000000 -0700
@@ -308,7 +308,7 @@
 	struct tcp_sock *tp = tcp_sk(sk);
 
 	tp->ecn_flags = 0;
-	if (sysctl_tcp_ecn == 1) {
+	if (sysctl_tcp_ecn == 1 || sysctl_tcp_dctcp_enable) {
 		TCP_SKB_CB(skb)->flags |= TCPHDR_ECE | TCPHDR_CWR;
 		tp->ecn_flags = TCP_ECN_OK;
 	}
@@ -851,7 +851,11 @@
 	th->ack_seq		= htonl(tp->rcv_nxt);
 	*(((__be16 *)th) + 6)	= htons(((tcp_header_size >> 2) << 12) |
 					tcb->flags);
-
+	/* Add by Peng for sending PACK packets */
+	if ( sysctl_tcp_pack && !(tcb->flags & TCPHDR_SYN) && skb->len != tcp_header_size)
+	{
+		*(((__be16 *)th) + 6)	= htons( ((tcp_header_size >> 2) << 12) | ((0x2) << 8) | tcb->flags);		
+	}
 	if (unlikely(tcb->flags & TCPHDR_SYN)) {
 		/* RFC1323: The window in SYN & SYN/ACK segments
 		 * is never scaled.
@@ -878,6 +882,9 @@
 	if (likely((tcb->flags & TCPHDR_SYN) == 0))
 		TCP_ECN_send(sk, skb, tcp_header_size);
 
+	/* In DCTCP, Assert ECT bit to all packets*/
+	if(sysctl_tcp_dctcp_enable)
+		INET_ECN_xmit(sk);
 #ifdef CONFIG_TCP_MD5SIG
 	/* Calculate the MD5 hash, as we have all we need now */
 	if (md5) {
@@ -2623,6 +2630,11 @@
 	tcp_init_nondata_skb(buff, tp->write_seq++, TCPHDR_SYN);
 	TCP_ECN_send_syn(sk, buff);
 
+	/* Initialize DCTCP internal parameters */
+	tp->next_seq = tp->snd_nxt; 
+	tp->acked_bytes_ecn = 0;
+	tp->acked_bytes_total = 0;
+	
 	/* Send it off. */
 	TCP_SKB_CB(buff)->when = tcp_time_stamp;
 	tp->retrans_stamp = TCP_SKB_CB(buff)->when;
@@ -2659,6 +2671,10 @@
 	int ato = icsk->icsk_ack.ato;
 	unsigned long timeout;
 
+	/* Delayed ACK reserved flag for DCTCP */
+	struct tcp_sock *tp = tcp_sk(sk);
+	tp->delayed_ack_reserved = 1;
+	
 	if (ato > TCP_DELACK_MIN) {
 		const struct tcp_sock *tp = tcp_sk(sk);
 		int max_ato = HZ / 2;
@@ -2710,6 +2726,10 @@
 {
 	struct sk_buff *buff;
 
+	/* Delayed ACK reserved flag for DCTCP */
+	struct tcp_sock *tp = tcp_sk(sk);
+	tp->delayed_ack_reserved = 0;
+	
 	/* If we have been reset, we may not send again. */
 	if (sk->sk_state == TCP_CLOSE)
 		return;
@@ -2801,6 +2821,7 @@
 
 		TCP_SKB_CB(skb)->flags |= TCPHDR_PSH;
 		TCP_SKB_CB(skb)->when = tcp_time_stamp;
+
 		err = tcp_transmit_skb(sk, skb, 1, GFP_ATOMIC);
 		if (!err)
 			tcp_event_new_data_sent(sk, skb);
